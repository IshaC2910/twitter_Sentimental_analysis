{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUeGQPBbJjOFCQ46AaJdC+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IshaC2910/twitter_Sentimental_analysis/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "n53sB5aP9_m4",
        "outputId": "bdaa337c-da0d-42f1-d9f4-4037ccb271ef"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-1-1511443087.py, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1-1511443087.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip install pandas scikit-learn\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "pip install pandas scikit-learn\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "Yd5ugu6U-yS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('./sentiment140/training.1600000.processed.noemoticon.csv', encoding='latin-1', header=None)\n",
        "df = df[[0, 5]]\n",
        "df.columns = ['polarity', 'text']\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqC-cOE9-6x5",
        "outputId": "4ea06467-0e8f-463f-c167-83bfb86e0618"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   polarity                                               text\n",
            "0         0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
            "1         0  is upset that he can't update his Facebook by ...\n",
            "2         0  @Kenichan I dived many times for the ball. Man...\n",
            "3         0    my whole body feels itchy and like its on fire \n",
            "4         0  @nationwideclass no, it's not behaving at all....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a20df48f",
        "outputId": "0be98830-acd2-4b41-de69-6a36fbc4ccf7"
      },
      "source": [
        "!pip install opendatasets\n",
        "import opendatasets as od\n",
        "\n",
        "od.download(\"https://www.kaggle.com/datasets/kazanova/sentiment140\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (from opendatasets) (1.7.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from opendatasets) (8.2.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (6.2.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2025.7.14)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.4.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (3.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from kaggle->opendatasets) (0.5.1)\n",
            "Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n",
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: ishaChoudhary2910\n",
            "Your Kaggle Key: ··········\n",
            "Dataset URL: https://www.kaggle.com/datasets/kazanova/sentiment140\n",
            "Downloading sentiment140.zip to ./sentiment140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 80.9M/80.9M [00:00<00:00, 953MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e18e10a"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['polarity'], test_size=0.2, random_state=42)\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=10000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c40e233f",
        "outputId": "c377ef55-ee47-4b63-8b8b-27e347d8684d"
      },
      "source": [
        "# Bernoulli Naive Bayes\n",
        "nb_model = BernoulliNB()\n",
        "nb_model.fit(X_train_tfidf, y_train)\n",
        "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
        "print(\"Bernoulli Naive Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
        "print(classification_report(y_test, y_pred_nb))\n",
        "\n",
        "# Logistic Regression\n",
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "lr_model.fit(X_train_tfidf, y_train)\n",
        "y_pred_lr = lr_model.predict(X_test_tfidf)\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "\n",
        "# Linear SVC\n",
        "svc_model = LinearSVC()\n",
        "svc_model.fit(X_train_tfidf, y_train)\n",
        "y_pred_svc = svc_model.predict(X_test_tfidf)\n",
        "print(\"Linear SVC Accuracy:\", accuracy_score(y_test, y_pred_svc))\n",
        "print(classification_report(y_test, y_pred_svc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bernoulli Naive Bayes Accuracy: 0.774803125\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.77      0.77    159494\n",
            "           4       0.77      0.78      0.78    160506\n",
            "\n",
            "    accuracy                           0.77    320000\n",
            "   macro avg       0.77      0.77      0.77    320000\n",
            "weighted avg       0.77      0.77      0.77    320000\n",
            "\n",
            "Logistic Regression Accuracy: 0.79508125\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.78      0.79    159494\n",
            "           4       0.79      0.81      0.80    160506\n",
            "\n",
            "    accuracy                           0.80    320000\n",
            "   macro avg       0.80      0.80      0.80    320000\n",
            "weighted avg       0.80      0.80      0.80    320000\n",
            "\n",
            "Linear SVC Accuracy: 0.79419375\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.78      0.79    159494\n",
            "           4       0.79      0.81      0.80    160506\n",
            "\n",
            "    accuracy                           0.79    320000\n",
            "   macro avg       0.79      0.79      0.79    320000\n",
            "weighted avg       0.79      0.79      0.79    320000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f67e9f19",
        "outputId": "3d31ace2-7f89-4820-9f23-51ac13dac87e"
      },
      "source": [
        "df = df[df['polarity'] != 2]\n",
        "df['polarity'] = df['polarity'].map({0: 0, 4: 1})\n",
        "print(df['polarity'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "polarity\n",
            "0    800000\n",
            "1    800000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51eb1038",
        "outputId": "b1d78759-fa30-4813-fd0d-a587040f075b"
      },
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    return text\n",
        "\n",
        "df['cleaned_text'] = df['text'].apply(clean_text)\n",
        "\n",
        "print(\"Original Text:\")\n",
        "print(df['text'].head())\n",
        "print(\"\\nCleaned Text:\")\n",
        "print(df['cleaned_text'].head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            "0    @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
            "1    is upset that he can't update his Facebook by ...\n",
            "2    @Kenichan I dived many times for the ball. Man...\n",
            "3      my whole body feels itchy and like its on fire \n",
            "4    @nationwideclass no, it's not behaving at all....\n",
            "Name: text, dtype: object\n",
            "\n",
            "Cleaned Text:\n",
            "0    @switchfoot http://twitpic.com/2y1zl - awww, t...\n",
            "1    is upset that he can't update his facebook by ...\n",
            "2    @kenichan i dived many times for the ball. man...\n",
            "3      my whole body feels itchy and like its on fire \n",
            "4    @nationwideclass no, it's not behaving at all....\n",
            "Name: cleaned_text, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76028dab"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_text'], df['polarity'], test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "496da7f3"
      },
      "source": [
        "vectorizer = TfidfVectorizer(max_features=10000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c387b05",
        "outputId": "66c8d1bd-0faa-41bb-cb5b-48fa1304b7c4"
      },
      "source": [
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=5000)\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "print(\"Shape of X_train_tfidf:\", X_train_tfidf.shape)\n",
        "print(\"Shape of X_test_tfidf:\", X_test_tfidf.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train_tfidf: (1280000, 5000)\n",
            "Shape of X_test_tfidf: (320000, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7ec9231",
        "outputId": "1187e645-00c4-4b42-deab-d25e024a5651"
      },
      "source": [
        "# Bernoulli Naive Bayes\n",
        "nb_model = BernoulliNB()\n",
        "nb_model.fit(X_train_tfidf, y_train)\n",
        "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
        "print(\"Bernoulli Naive Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
        "print(classification_report(y_test, y_pred_nb))\n",
        "\n",
        "# Logistic Regression\n",
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "lr_model.fit(X_train_tfidf, y_train)\n",
        "y_pred_lr = lr_model.predict(X_test_tfidf)\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "\n",
        "# Linear SVC\n",
        "svc_model = LinearSVC()\n",
        "svc_model.fit(X_train_tfidf, y_train)\n",
        "y_pred_svc = svc_model.predict(X_test_tfidf)\n",
        "print(\"Linear SVC Accuracy:\", accuracy_score(y_test, y_pred_svc))\n",
        "print(classification_report(y_test, y_pred_svc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bernoulli Naive Bayes Accuracy: 0.766478125\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.75      0.76    159494\n",
            "           1       0.76      0.78      0.77    160506\n",
            "\n",
            "    accuracy                           0.77    320000\n",
            "   macro avg       0.77      0.77      0.77    320000\n",
            "weighted avg       0.77      0.77      0.77    320000\n",
            "\n",
            "Logistic Regression Accuracy: 0.79539375\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.78      0.79    159494\n",
            "           1       0.79      0.81      0.80    160506\n",
            "\n",
            "    accuracy                           0.80    320000\n",
            "   macro avg       0.80      0.80      0.80    320000\n",
            "weighted avg       0.80      0.80      0.80    320000\n",
            "\n",
            "Linear SVC Accuracy: 0.79528125\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.78      0.79    159494\n",
            "           1       0.79      0.81      0.80    160506\n",
            "\n",
            "    accuracy                           0.80    320000\n",
            "   macro avg       0.80      0.80      0.80    320000\n",
            "weighted avg       0.80      0.80      0.80    320000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e6499fc",
        "outputId": "90352f91-955e-4398-a8fb-c877d9d11056"
      },
      "source": [
        "svc_model = LinearSVC(max_iter=1000)\n",
        "svc_model.fit(X_train_tfidf, y_train)\n",
        "y_pred_svc = svc_model.predict(X_test_tfidf)\n",
        "print(\"Linear SVC Accuracy:\", accuracy_score(y_test, y_pred_svc))\n",
        "print(classification_report(y_test, y_pred_svc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear SVC Accuracy: 0.79528125\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.78      0.79    159494\n",
            "           1       0.79      0.81      0.80    160506\n",
            "\n",
            "    accuracy                           0.80    320000\n",
            "   macro avg       0.80      0.80      0.80    320000\n",
            "weighted avg       0.80      0.80      0.80    320000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9e07d9e",
        "outputId": "359ec286-cae4-48e3-c2e3-04181e56f320"
      },
      "source": [
        "lr_model = LogisticRegression(max_iter=100)\n",
        "lr_model.fit(X_train_tfidf, y_train)\n",
        "y_pred_lr = lr_model.predict(X_test_tfidf)\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
        "print(classification_report(y_test, y_pred_lr))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.79539375\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.78      0.79    159494\n",
            "           1       0.79      0.81      0.80    160506\n",
            "\n",
            "    accuracy                           0.80    320000\n",
            "   macro avg       0.80      0.80      0.80    320000\n",
            "weighted avg       0.80      0.80      0.80    320000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81f682ce",
        "outputId": "62677589-afac-4b73-cef7-5404e0f6c384"
      },
      "source": [
        "sample_tweets = [\n",
        "    \"I love this movie! It's so funny and heartwarming.\",\n",
        "    \"This is the worst movie I have ever seen. It was so boring.\",\n",
        "    \"I'm not sure how I feel about this movie. It was okay, I guess.\"\n",
        "]\n",
        "\n",
        "sample_tweets_tfidf = vectorizer.transform(sample_tweets)\n",
        "\n",
        "# Predict with Bernoulli Naive Bayes\n",
        "nb_predictions = nb_model.predict(sample_tweets_tfidf)\n",
        "print(\"Bernoulli Naive Bayes Predictions:\", nb_predictions)\n",
        "\n",
        "# Predict with SVM\n",
        "svc_predictions = svc_model.predict(sample_tweets_tfidf)\n",
        "print(\"SVM Predictions:\", svc_predictions)\n",
        "\n",
        "# Predict with Logistic Regression\n",
        "lr_predictions = lr_model.predict(sample_tweets_tfidf)\n",
        "print(\"Logistic Regression Predictions:\", lr_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bernoulli Naive Bayes Predictions: [1 0 0]\n",
            "SVM Predictions: [1 0 0]\n",
            "Logistic Regression Predictions: [1 0 0]\n"
          ]
        }
      ]
    }
  ]
}